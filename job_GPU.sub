#!/bin/bash
#SBATCH --job-name="pytorch_job"
#SBATCH --output="pytorch_job.%j.out"
#SBATCH --error="pytorch_job.%j.err"
#SBATCH --partition=ghx4
#SBATCH -t 03:00:00
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1 # could be 1 for py-torch
#SBATCH --gpus-per-node=1
#SBATCH --gpu-bind=closest   # select a cpu close to gpu on pci bus topology
#SBATCH --cpus-per-task=4   # spread out to use 1 core per numa, set to 64 if tasks is 1
#SBATCH --mem=16G
#SBATCH --account=beeh-dtai-gh
#SBATCH --mail-user=chihlul1@uci.edu
#SBATCH --mail-type="BEGIN,END" 


# Load the PyTorch module
module load python/miniforge3_pytorch/2.7.0
date
# Run your script
python session1.py
date